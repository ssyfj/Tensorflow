{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter: 0, Testing accuracy:0.952500----learn rate:0.001000\n",
      "Iter: 1, Testing accuracy:0.959800----learn rate:0.000950\n",
      "Iter: 2, Testing accuracy:0.967800----learn rate:0.000903\n",
      "Iter: 3, Testing accuracy:0.972100----learn rate:0.000857\n",
      "Iter: 4, Testing accuracy:0.972000----learn rate:0.000815\n",
      "Iter: 5, Testing accuracy:0.972900----learn rate:0.000774\n",
      "Iter: 6, Testing accuracy:0.976000----learn rate:0.000735\n",
      "Iter: 7, Testing accuracy:0.976200----learn rate:0.000698\n",
      "Iter: 8, Testing accuracy:0.973800----learn rate:0.000663\n",
      "Iter: 9, Testing accuracy:0.976100----learn rate:0.000630\n",
      "Iter: 10, Testing accuracy:0.977100----learn rate:0.000599\n",
      "Iter: 11, Testing accuracy:0.976900----learn rate:0.000569\n",
      "Iter: 12, Testing accuracy:0.978900----learn rate:0.000540\n",
      "Iter: 13, Testing accuracy:0.980300----learn rate:0.000513\n",
      "Iter: 14, Testing accuracy:0.979900----learn rate:0.000488\n",
      "Iter: 15, Testing accuracy:0.978500----learn rate:0.000463\n",
      "Iter: 16, Testing accuracy:0.978000----learn rate:0.000440\n",
      "Iter: 17, Testing accuracy:0.978600----learn rate:0.000418\n",
      "Iter: 18, Testing accuracy:0.979100----learn rate:0.000397\n",
      "Iter: 19, Testing accuracy:0.980700----learn rate:0.000377\n",
      "Iter: 20, Testing accuracy:0.981300----learn rate:0.000358\n",
      "Iter: 21, Testing accuracy:0.979600----learn rate:0.000341\n",
      "Iter: 22, Testing accuracy:0.980000----learn rate:0.000324\n",
      "Iter: 23, Testing accuracy:0.980200----learn rate:0.000307\n",
      "Iter: 24, Testing accuracy:0.977800----learn rate:0.000292\n",
      "Iter: 25, Testing accuracy:0.981000----learn rate:0.000277\n",
      "Iter: 26, Testing accuracy:0.979900----learn rate:0.000264\n",
      "Iter: 27, Testing accuracy:0.980700----learn rate:0.000250\n",
      "Iter: 28, Testing accuracy:0.979500----learn rate:0.000238\n",
      "Iter: 29, Testing accuracy:0.979600----learn rate:0.000226\n",
      "Iter: 30, Testing accuracy:0.980500----learn rate:0.000215\n",
      "Iter: 31, Testing accuracy:0.981100----learn rate:0.000204\n",
      "Iter: 32, Testing accuracy:0.981600----learn rate:0.000194\n",
      "Iter: 33, Testing accuracy:0.981600----learn rate:0.000184\n",
      "Iter: 34, Testing accuracy:0.979300----learn rate:0.000175\n",
      "Iter: 35, Testing accuracy:0.980800----learn rate:0.000166\n",
      "Iter: 36, Testing accuracy:0.981200----learn rate:0.000158\n",
      "Iter: 37, Testing accuracy:0.981400----learn rate:0.000150\n",
      "Iter: 38, Testing accuracy:0.981300----learn rate:0.000142\n",
      "Iter: 39, Testing accuracy:0.981000----learn rate:0.000135\n",
      "Iter: 40, Testing accuracy:0.980400----learn rate:0.000129\n",
      "Iter: 41, Testing accuracy:0.980100----learn rate:0.000122\n",
      "Iter: 42, Testing accuracy:0.981600----learn rate:0.000116\n",
      "Iter: 43, Testing accuracy:0.980400----learn rate:0.000110\n",
      "Iter: 44, Testing accuracy:0.981400----learn rate:0.000105\n",
      "Iter: 45, Testing accuracy:0.981500----learn rate:0.000099\n",
      "Iter: 46, Testing accuracy:0.982400----learn rate:0.000094\n",
      "Iter: 47, Testing accuracy:0.982000----learn rate:0.000090\n",
      "Iter: 48, Testing accuracy:0.981500----learn rate:0.000085\n",
      "Iter: 49, Testing accuracy:0.981000----learn rate:0.000081\n",
      "Iter: 50, Testing accuracy:0.981700----learn rate:0.000077\n"
     ]
    }
   ],
   "source": [
    "#数据载入---有其他方法\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True) #注意输出标签是one_hot类型\n",
    "\n",
    "#按批次进行计算\n",
    "#设置每个批次大小\n",
    "batch_size = 100\n",
    "#获取批次数量，注意：我们训练时使用的是mnist.train训练集数据\n",
    "n_batch = mnist.train.num_examples // batch_size #注意：//也是除法，返回整数\n",
    "\n",
    "#开始定义占位符号\n",
    "x = tf.placeholder(tf.float32,[None,784]) #由于每张图片都是28×28像素，所以每个样本的特征都是784\n",
    "y = tf.placeholder(tf.float32,[None,10]) #是分10类\n",
    "keep_prob = tf.placeholder(tf.float32) #设置全局dropout参数,即设置每个神经元正常工作的概率\n",
    "lr = tf.Variable(0.001,dtype=tf.float32) #学习率设置\n",
    "\n",
    "#开始创建一个神经网络隐藏层L1含有10个激活单元\n",
    "Weight_L1 = tf.Variable(tf.truncated_normal([784,500],stddev=0.1)) #产生截断正态分布随机数，取值范围为[ mean - 2 * stddev, mean + 2 * stddev ]  截断的产生正态分布的随机数，即随机数与均值的差值若大于两倍的标准差，则重新生成\n",
    "biases_L1 = tf.Variable(tf.zeros([1,500])+0.1) #对于偏执单元的权重，我们没有必要进行随机初始化,但是可以设置初始值\n",
    "Wx_plus_b_L1 = tf.matmul(x,Weight_L1)+biases_L1\n",
    "L1 = tf.nn.tanh(Wx_plus_b_L1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob) #设置该L1层的dropout信息\n",
    "\n",
    "Weight_L2 = tf.Variable(tf.truncated_normal([500,300],stddev=0.1)) #产生截断正态分布随机数，取值范围为[ mean - 2 * stddev, mean + 2 * stddev ]  截断的产生正态分布的随机数，即随机数与均值的差值若大于两倍的标准差，则重新生成\n",
    "biases_L2 = tf.Variable(tf.zeros([1,300])+0.1) #对于偏执单元的权重，我们没有必要进行随机初始化,但是可以设置初始值\n",
    "Wx_plus_b_L2 = tf.matmul(L1_drop,Weight_L2)+biases_L2\n",
    "L2 = tf.nn.tanh(Wx_plus_b_L2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob) #设置该L1层的dropout信息\n",
    "\n",
    "Weight_L3 = tf.Variable(tf.truncated_normal([300,200],stddev=0.1)) #产生截断正态分布随机数，取值范围为[ mean - 2 * stddev, mean + 2 * stddev ]  截断的产生正态分布的随机数，即随机数与均值的差值若大于两倍的标准差，则重新生成\n",
    "biases_L3 = tf.Variable(tf.zeros([1,200])+0.1) #对于偏执单元的权重，我们没有必要进行随机初始化,但是可以设置初始值\n",
    "Wx_plus_b_L3 = tf.matmul(L2_drop,Weight_L3)+biases_L3\n",
    "L3 = tf.nn.tanh(Wx_plus_b_L3)\n",
    "L3_drop = tf.nn.dropout(L3,keep_prob) #设置该L1层的dropout信息\n",
    "\n",
    "Weight_L4 = tf.Variable(tf.truncated_normal([200,10],stddev=0.1)) #产生截断正态分布随机数，取值范围为[ mean - 2 * stddev, mean + 2 * stddev ]  截断的产生正态分布的随机数，即随机数与均值的差值若大于两倍的标准差，则重新生成\n",
    "biases_L4 = tf.Variable(tf.zeros([1,10])+0.1) #对于偏执单元的权重，我们没有必要进行随机初始化,但是可以设置初始值\n",
    "Wx_plus_b_L4 = tf.matmul(L3_drop,Weight_L4)+biases_L4\n",
    "y_pred = tf.nn.softmax(Wx_plus_b_L4)\n",
    "\n",
    "#定义代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=y_pred)) #这里我们使用交叉熵进行处理，使得加快训练速度\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#获取结果存放在bool列表中\n",
    "correct_prediction = tf.equal(tf.arg_max(y,1),tf.arg_max(y_pred,1)) #注意：arg_max第二个参数是指定坐标信息，因为结果按行存储，所以1\n",
    "#根据上面的bool列表，获取准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) #tf.cast格式转换后，求解平均值\n",
    "\n",
    "\n",
    "#开启会话\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for iter_cnt in range(51): #整体数据迭代\n",
    "        sess.run(tf.assign(lr,0.001*(0.95**iter_cnt))) #随着迭代次数，降低学习率，防止发散\n",
    "        for batch_cnt in range(n_batch): #小批次数据分批次迭代\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size) #依照batch_size获取下一批次数据\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0}) #传入数据，进行训练。对于隐藏层每一层随机使用70%的激活单元正常工作，另外30%不工作防止过拟合\n",
    "            \n",
    "        #获取每一次整体数据迭代后的准确率\n",
    "        #在我们进行训练权值时，我们需要设置dropout参数去降低拟合程度，我们训练完毕以后，需要我们预测时，是不需要进行甚至dropout参数的，所以下面我们都是设置为1\n",
    "        test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0}) #注意：预测时，我们也要传入数据，并且传入的是测试集数据\n",
    "        learn_rate = sess.run(lr)\n",
    "        print(\"Iter: %d, Testing accuracy:%f----learn rate:%f\"%(iter_cnt,test_acc,learn_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iter: 48, Testing accuracy:0.981500----learn rate:0.000085\n",
    "Iter: 49, Testing accuracy:0.981000----learn rate:0.000081\n",
    "Iter: 50, Testing accuracy:0.981700----learn rate:0.000077"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
